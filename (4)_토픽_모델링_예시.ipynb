{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehgkor/lhg/blob/main/(4)_%ED%86%A0%ED%94%BD_%EB%AA%A8%EB%8D%B8%EB%A7%81_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: 필요한 라이브러리 설치 및 임포트\n",
        "\n",
        "!pip install pandas matplotlib scikit-learn\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # 문서-단어 행렬 생성\n",
        "from sklearn.decomposition import LatentDirichletAllocation  # LDA 모델 생성\n",
        "import pandas as pd  # 데이터프레임 작업\n"
      ],
      "metadata": {
        "id": "m-Ol1EkiyYm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead0d425-2163-4f61-96a3-9e3af28d9b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 2: 텍스트 입력\n",
        "\n",
        "all_text = [\"세종 대왕 상형 한글 문자\",\n",
        "            \"꽁꽁 얼어붙은 한강 고양이\",\n",
        "            \"이집트 상형 문자 파피루스 고양이\"]\n",
        "\n",
        "print(\"텍스트 데이터 읽기 완료!\")\n"
      ],
      "metadata": {
        "id": "nYmuAwpXSxfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3799b833-6703-4859-ca96-c76fb42fdb71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텍스트 데이터 읽기 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 3: 텍스트 전처리 및 BoW 임베딩\n",
        "\n",
        "X = CountVectorizer()\n",
        "X.fit(all_text) # 단어 사전 생성\n",
        "dtm = X.transform(all_text) # 문서-단어 행렬 생성\n",
        "\n",
        "df_dtm = pd.DataFrame(dtm.toarray(), columns=X.get_feature_names_out())\n",
        "word_features = X.get_feature_names_out()\n",
        "print(df_dtm)\n"
      ],
      "metadata": {
        "id": "dIyGLkL-TFMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd71e819-15cc-4531-c6b3-399c45ae0623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   고양이  꽁꽁  대왕  문자  상형  세종  얼어붙은  이집트  파피루스  한강  한글\n",
            "0    0   0   1   1   1   1     0    0     0   0   1\n",
            "1    1   1   0   0   0   0     1    0     0   1   0\n",
            "2    1   0   0   1   1   0     0    1     1   0   0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: LDA 모델 실행\n",
        "\n",
        "num_topics = 2  # 추출할 토픽 수\n",
        "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "lda.fit(df_dtm)\n",
        "\n",
        "# 토픽별 주요 단어 출력\n",
        "def print_topics(model, feature_names, num_top_words=3):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"토픽 {topic_idx + 1}:\")\n",
        "        print(\", \".join([feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]))\n",
        "\n",
        "print(\"토픽 모델링 결과:\")\n",
        "print_topics(lda, word_features)"
      ],
      "metadata": {
        "id": "I7Ad0LIqZ1DW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9bdca47-bd7b-4cf4-aab2-f93f7cb74c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토픽 모델링 결과:\n",
            "토픽 1:\n",
            "상형, 문자, 세종\n",
            "토픽 2:\n",
            "고양이, 얼어붙은, 한강\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: 문서별 토픽 분포 확인\n",
        "\n",
        "document_topic_matrix = lda.transform(df_dtm)  # 문서-토픽 분포 행렬\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "df_document_topics = pd.DataFrame(document_topic_matrix, columns=[f\"토픽 {i+1}\" for i in range(num_topics)])\n",
        "print(\"\\n문서별 토픽 분포:\")\n",
        "print(df_document_topics)"
      ],
      "metadata": {
        "id": "z1W9k9vvaSf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77b237d-54d5-4224-b994-d0076224eb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "문서별 토픽 분포:\n",
            "       토픽 1      토픽 2\n",
            "0  0.911644  0.088356\n",
            "1  0.106543  0.893457\n",
            "2  0.898969  0.101031\n"
          ]
        }
      ]
    }
  ]
}